{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f3ec1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.utils import shuffle\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Cropping2D, Flatten, Dense, Convolution2D, Dropout, Lambda\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223960d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added 4896 dates from: t1-center\n",
      "added 6546 dates from: t3-center-reverse\n",
      "added 3594 dates from: t8-recovery\n",
      "added 1800 dates from: t9-hard-recovery\n",
      "added 1983 dates from: t10-recovery-normal-lines\n",
      "added 24108 dates from: data_udacity\n",
      "total data = 42927\n"
     ]
    }
   ],
   "source": [
    "# Add which test to read. Set whether to use the right and left image in each test.\n",
    "# \"use_sides\": True -> if use left and right cameras for traning (only when recording in center position)\n",
    "# \"turning\" -> direction of circulation\n",
    "records = [\n",
    "    {\"name\": \"t1-center\", \"use_sides\": True} ,\n",
    "#     {\"name\": \"t2-center\", \"use_sides\": True} ,\n",
    "    {\"name\": \"t3-center-reverse\", \"use_sides\": True} ,\n",
    "#     {\"name\": \"t4-center-reverse\", \"use_sides\": True} ,\n",
    "    {\"name\": \"t8-recovery\", \"use_sides\": True} ,\n",
    "    {\"name\": \"t9-hard-recovery\", \"use_sides\": True} ,\n",
    "    {\"name\": \"t10-recovery-normal-lines\", \"use_sides\": True} ,\n",
    "    {\"name\": \"data_udacity\", \"use_sides\": True}\n",
    "]\n",
    "\n",
    "# Read CSVs\n",
    "samples_array = [[],[]]\n",
    "data_len = 0\n",
    "for record in records:\n",
    "    with open('./data/'+record[\"name\"]+'/driving_log.csv') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for line in reader:\n",
    "            center_img = line[0]\n",
    "            steering = float(line[3])\n",
    "            samples_array[0].append(center_img)\n",
    "            samples_array[1].append(steering)\n",
    "            \n",
    "            if record[\"use_sides\"]:\n",
    "                correction = 0.25\n",
    "                steering_left = steering + correction\n",
    "                steering_right = steering - correction\n",
    "                    \n",
    "                left_img = line[1]\n",
    "                samples_array[0].append(left_img)\n",
    "                samples_array[1].append(steering_left)\n",
    "                \n",
    "                right_img = line[2]\n",
    "                samples_array[0].append(right_img)\n",
    "                samples_array[1].append(steering_right)\n",
    "                \n",
    "    new_len = len(samples_array[0])-data_len\n",
    "    data_len += new_len\n",
    "    print(\"added \"+str(new_len)+\" dates from: \"+record[\"name\"])\n",
    "        \n",
    "samples_array = np.array(samples_array).T\n",
    "print(\"total data = \"+str(len(samples_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "583c34ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img_route = './data/t5-center-hard-curves/IMG/center_2021_07_20_20_24_41_681.jpg'\n",
    "# test_img = cv2.imread(test_img_route)\n",
    "# crop_img = test_img[50:70, 0:1000]\n",
    "# plt.imshow(crop_img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192eb99c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "steering = samples_array[:,1].astype(np.float)\n",
    "n, bins, p = plt.hist(steering, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "594882fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Crop high peaks of histogram\n",
    "bins_cropped = 3\n",
    "\n",
    "n = np.array(n)\n",
    "crop_index = n.argsort()[-bins_cropped:]\n",
    "crop_index = np.flip(crop_index)\n",
    "\n",
    "remove_indx = []\n",
    "for i in range(bins_cropped):\n",
    "    indx_delete = crop_index[i]\n",
    "    new_bean_values = (n[indx_delete+1]+n[indx_delete-1])/2 # mean of neighbors beans. This will be the new value of cropped bean\n",
    "    nro_delete = np.int(n[crop_index[i]]-new_bean_values) # amount to delete\n",
    "    \n",
    "    indx = np.where((bins[indx_delete]<=steering) & (steering<bins[indx_delete+1]))\n",
    "    indx = np.ravel(indx)\n",
    "    np.random.shuffle(indx)\n",
    "    remove_indx.extend(indx[0:nro_delete])\n",
    "\n",
    "samples_array_balanced = []\n",
    "for i , s in enumerate(samples_array):\n",
    "    if i not in remove_indx:\n",
    "        samples_array_balanced.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54720621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "steering = np.array(samples_array_balanced)[:,1].astype(np.float)\n",
    "sns.displot(steering,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d802c",
   "metadata": {},
   "source": [
    "#### Nvidia End to End Learning for Self-Driving Cars\n",
    "Paper: https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "<img src=\"nvidia-net.png\" alt=\"NvidiaE2ENet\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72e9aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "    ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "\n",
    "    # Model: Nvidia End to End Learning for Self-Driving Cars\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Preprocess incoming data, crop interest zone\n",
    "    model.add(Cropping2D(cropping=((60,20), (0,0)), input_shape=(160,320,3)))\n",
    "    # Preprocess incoming data, centered around zero with small standard deviation \n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.))\n",
    "\n",
    "    model.add(Convolution2D(24, (5, 5), strides=(2, 2), activation='relu'))\n",
    "    model.add(Convolution2D(36, (5, 5), strides=(2, 2), activation='relu'))\n",
    "    model.add(Convolution2D(48, (5, 5), strides=(2, 2), activation='relu'))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c9266c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from keras import backend as K\n",
    "# inp = model.input                                           # input placeholder\n",
    "# outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "# functors = [K.function([inp], [out]) for out in outputs]    # evaluation functions\n",
    "\n",
    "# # Testing\n",
    "# test_img_route = './data/t5-center-hard-curves/IMG/center_2021_07_20_20_24_41_681.jpg'\n",
    "# test_img = cv2.imread(test_img_route)\n",
    "# test_img = np.expand_dims(test_img, axis=0)\n",
    "# print(test_img.shape)\n",
    "# input_shape=(160,320,3)\n",
    "# layer_outs = [func([test_img, 1.]) for func in functors]\n",
    "\n",
    "# # Display normalized output\n",
    "# a = np.array(layer_outs[1])[0][0]\n",
    "# plt.imshow(a)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6263794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_contrast(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    scale = np.random.uniform(.6, 1.2)\n",
    "    hsv[:, :, 2] = hsv[:, :, 2] * scale\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def generator(samples_array, batch_size=32, traning_mode = False):\n",
    "    num_samples = len(samples_array[0])\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples_array)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples_array[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                file_name = batch_sample[0].split(\"\\\\\")[-1]\n",
    "                test_name = batch_sample[0].split(\"\\\\\")[-3]\n",
    "                name = './data/'+test_name+'/IMG/'+batch_sample[0].split(\"\\\\\")[-1]\n",
    "                img = cv2.imread(name)\n",
    "                ang = float(batch_sample[1])\n",
    "                \n",
    "                # Generate random flipped images\n",
    "                # Only for training (we should not augment validation data)\n",
    "                if(traning_mode):\n",
    "                    if np.random.rand() < 0.5:\n",
    "                        img = np.fliplr(img)\n",
    "                        ang = -ang\n",
    "                    # Change contrast randomly\n",
    "                    if np.random.rand() < 0.5:                    \n",
    "                        img = change_contrast(img)\n",
    "                \n",
    "                images.append(img)\n",
    "                angles.append(ang)\n",
    "\n",
    "            # Trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d82fb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "118/118 [==============================] - 144s 1s/step - loss: 0.0434 - val_loss: 0.0358\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03575, saving model to ./weights.best.hdf5\n",
      "Epoch 2/100\n",
      "118/118 [==============================] - 143s 1s/step - loss: 0.0353 - val_loss: 0.0247\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03575 to 0.02474, saving model to ./weights.best.hdf5\n",
      "Epoch 3/100\n",
      "118/118 [==============================] - 143s 1s/step - loss: 0.0332 - val_loss: 0.0287\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02474\n",
      "Epoch 4/100\n",
      "118/118 [==============================] - 144s 1s/step - loss: 0.0317 - val_loss: 0.0243\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02474 to 0.02428, saving model to ./weights.best.hdf5\n",
      "Epoch 5/100\n",
      "118/118 [==============================] - 143s 1s/step - loss: 0.0303 - val_loss: 0.0254\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02428\n",
      "Epoch 6/100\n",
      "118/118 [==============================] - 143s 1s/step - loss: 0.0288 - val_loss: 0.0262\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02428\n",
      "Epoch 7/100\n",
      "118/118 [==============================] - 140s 1s/step - loss: 0.0287 - val_loss: 0.0244\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02428\n",
      "Epoch 8/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0276 - val_loss: 0.0302\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02428\n",
      "Epoch 9/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0274 - val_loss: 0.0289\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02428\n",
      "Epoch 10/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0261 - val_loss: 0.0222\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02428 to 0.02217, saving model to ./weights.best.hdf5\n",
      "Epoch 11/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0255 - val_loss: 0.0229\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02217\n",
      "Epoch 12/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0248 - val_loss: 0.0254\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02217\n",
      "Epoch 13/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0249 - val_loss: 0.0225\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02217\n",
      "Epoch 14/100\n",
      "118/118 [==============================] - 139s 1s/step - loss: 0.0237 - val_loss: 0.0231\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.02217\n",
      "Epoch 15/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0231 - val_loss: 0.0218\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02217 to 0.02184, saving model to ./weights.best.hdf5\n",
      "Epoch 16/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0230 - val_loss: 0.0201\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02184 to 0.02010, saving model to ./weights.best.hdf5\n",
      "Epoch 17/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0222 - val_loss: 0.0200\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.02010 to 0.02002, saving model to ./weights.best.hdf5\n",
      "Epoch 18/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0222 - val_loss: 0.0219\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02002\n",
      "Epoch 19/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0212 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02002\n",
      "Epoch 20/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0205 - val_loss: 0.0208\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02002\n",
      "Epoch 21/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0208 - val_loss: 0.0191\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.02002 to 0.01909, saving model to ./weights.best.hdf5\n",
      "Epoch 22/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0198 - val_loss: 0.0217\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01909\n",
      "Epoch 23/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0197 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01909\n",
      "Epoch 24/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0182 - val_loss: 0.0254\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01909\n",
      "Epoch 25/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0183 - val_loss: 0.0188\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01909 to 0.01878, saving model to ./weights.best.hdf5\n",
      "Epoch 26/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0177 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01878\n",
      "Epoch 27/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0173 - val_loss: 0.0227\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01878\n",
      "Epoch 28/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0170 - val_loss: 0.0135\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01878 to 0.01353, saving model to ./weights.best.hdf5\n",
      "Epoch 29/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0161 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01353\n",
      "Epoch 30/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0162 - val_loss: 0.0154\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01353\n",
      "Epoch 31/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0158 - val_loss: 0.0141\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01353\n",
      "Epoch 32/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0152 - val_loss: 0.0155\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01353\n",
      "Epoch 33/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0150 - val_loss: 0.0127\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01353 to 0.01270, saving model to ./weights.best.hdf5\n",
      "Epoch 34/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0149 - val_loss: 0.0169\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01270\n",
      "Epoch 35/100\n",
      "118/118 [==============================] - 141s 1s/step - loss: 0.0146 - val_loss: 0.0158\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01270\n",
      "Epoch 36/100\n",
      "118/118 [==============================] - 143s 1s/step - loss: 0.0151 - val_loss: 0.0161\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.01270\n",
      "Epoch 37/100\n",
      "118/118 [==============================] - 144s 1s/step - loss: 0.0144 - val_loss: 0.0150\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.01270\n",
      "Epoch 38/100\n",
      "118/118 [==============================] - 144s 1s/step - loss: 0.0140 - val_loss: 0.0154\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01270\n",
      "Epoch 39/100\n",
      "118/118 [==============================] - 144s 1s/step - loss: 0.0140 - val_loss: 0.0135\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.01270\n",
      "Epoch 40/100\n",
      "118/118 [==============================] - 144s 1s/step - loss: 0.0139 - val_loss: 0.0134\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01270\n",
      "Epoch 41/100\n",
      "118/118 [==============================] - 144s 1s/step - loss: 0.0134 - val_loss: 0.0149\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.01270\n",
      "Epoch 42/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0134 - val_loss: 0.0169\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.01270\n",
      "Epoch 43/100\n",
      "118/118 [==============================] - 139s 1s/step - loss: 0.0137 - val_loss: 0.0161\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.01270\n",
      "Epoch 44/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0134 - val_loss: 0.0143\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.01270\n",
      "Epoch 45/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0129 - val_loss: 0.0197\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.01270\n",
      "Epoch 46/100\n",
      "118/118 [==============================] - 139s 1s/step - loss: 0.0129 - val_loss: 0.0138\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.01270\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 139s 1s/step - loss: 0.0127 - val_loss: 0.0140\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.01270\n",
      "Epoch 48/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0128 - val_loss: 0.0176\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.01270\n",
      "Epoch 49/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0126 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.01270\n",
      "Epoch 50/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0122 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.01270\n",
      "Epoch 51/100\n",
      "118/118 [==============================] - 141s 1s/step - loss: 0.0124 - val_loss: 0.0173\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.01270\n",
      "Epoch 52/100\n",
      "118/118 [==============================] - 143s 1s/step - loss: 0.0124 - val_loss: 0.0136\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.01270\n",
      "Epoch 53/100\n",
      "118/118 [==============================] - 144s 1s/step - loss: 0.0119 - val_loss: 0.0230\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.01270\n",
      "Epoch 54/100\n",
      "118/118 [==============================] - 144s 1s/step - loss: 0.0118 - val_loss: 0.0147\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.01270\n",
      "Epoch 55/100\n",
      "118/118 [==============================] - 145s 1s/step - loss: 0.0114 - val_loss: 0.0160\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.01270\n",
      "Epoch 56/100\n",
      "118/118 [==============================] - 144s 1s/step - loss: 0.0117 - val_loss: 0.0134\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.01270\n",
      "Epoch 57/100\n",
      "118/118 [==============================] - 144s 1s/step - loss: 0.0111 - val_loss: 0.0171\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.01270\n",
      "Epoch 58/100\n",
      "118/118 [==============================] - 139s 1s/step - loss: 0.0114 - val_loss: 0.0177\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.01270\n",
      "Epoch 59/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0111 - val_loss: 0.0144\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.01270\n",
      "Epoch 60/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0109 - val_loss: 0.0151\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.01270\n",
      "Epoch 61/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0110 - val_loss: 0.0173\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.01270\n",
      "Epoch 62/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0110 - val_loss: 0.0140\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.01270\n",
      "Epoch 63/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0108 - val_loss: 0.0138\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.01270\n",
      "Epoch 64/100\n",
      "118/118 [==============================] - 139s 1s/step - loss: 0.0107 - val_loss: 0.0158\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.01270\n",
      "Epoch 65/100\n",
      "118/118 [==============================] - 139s 1s/step - loss: 0.0109 - val_loss: 0.0132\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.01270\n",
      "Epoch 66/100\n",
      "118/118 [==============================] - 139s 1s/step - loss: 0.0105 - val_loss: 0.0148\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.01270\n",
      "Epoch 67/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0100 - val_loss: 0.0132\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.01270\n",
      "Epoch 68/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0103 - val_loss: 0.0115\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.01270 to 0.01153, saving model to ./weights.best.hdf5\n",
      "Epoch 69/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0103 - val_loss: 0.0152\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.01153\n",
      "Epoch 70/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0102 - val_loss: 0.0152\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.01153\n",
      "Epoch 71/100\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0102 - val_loss: 0.0163\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.01153\n",
      "Epoch 72/100\n",
      "118/118 [==============================] - 143s 1s/step - loss: 0.0099 - val_loss: 0.0143\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.01153\n",
      "Epoch 73/100\n",
      "118/118 [==============================] - 143s 1s/step - loss: 0.0099 - val_loss: 0.0231\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.01153\n",
      "Epoch 74/100\n",
      "118/118 [==============================] - 143s 1s/step - loss: 0.0097 - val_loss: 0.0123\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.01153\n",
      "Epoch 75/100\n",
      "118/118 [==============================] - 144s 1s/step - loss: 0.0097 - val_loss: 0.0139\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.01153\n",
      "Epoch 76/100\n",
      "118/118 [==============================] - 143s 1s/step - loss: 0.0096 - val_loss: 0.0157\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.01153\n",
      "Epoch 77/100\n",
      "118/118 [==============================] - 143s 1s/step - loss: 0.0095 - val_loss: 0.0117\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.01153\n",
      "Epoch 78/100\n",
      "118/118 [==============================] - 145s 1s/step - loss: 0.0097 - val_loss: 0.0177\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.01153\n",
      "Epoch 79/100\n",
      "114/118 [===========================>..] - ETA: 4s - loss: 0.0094"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a9df3645bd87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m             epochs=100, callbacks=callbacks_list, verbose=1)\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set our batch size\n",
    "batch_size=256\n",
    "\n",
    "# Split in train/validation\n",
    "shuffle(samples_array_balanced)\n",
    "train_samples, validation_samples = train_test_split(samples_array_balanced, test_size=0.3)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=batch_size, traning_mode  = True)\n",
    "validation_generator = generator(validation_samples, batch_size=batch_size, traning_mode  = False)\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "# checkpoints_filepath=\"./checkpoints/weights-improvement-{epoch:02d}.hdf5\"\n",
    "checkpoints_filepath=\"./weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(checkpoints_filepath, monitor='val_loss', \n",
    "                             verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0)\n",
    "# callbacks_list = [checkpoint,es]\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history_object = model.fit_generator(train_generator,\n",
    "            steps_per_epoch=ceil(len(train_samples)/batch_size),\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=ceil(len(validation_samples)/batch_size),\n",
    "            epochs=100, callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e675de9f",
   "metadata": {},
   "source": [
    "## Load and continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdec3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set our batch size\n",
    "# batch_size=256\n",
    "\n",
    "# # Split in train/validation\n",
    "# shuffle(samples_array_balanced)\n",
    "# train_samples, validation_samples = train_test_split(samples_array_balanced, test_size=0.3)\n",
    "\n",
    "# model = load_model('./model.h5')\n",
    "\n",
    "# optimizer = optimizers.Adam(lr=0.0001)\n",
    "# model.compile(loss='mse', optimizer=optimizer)\n",
    "\n",
    "# checkpoints_filepath=\"./weights_retrained.best.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(checkpoints_filepath, monitor='val_loss', \n",
    "#                              verbose=1, save_best_only=True, mode='min')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "# history_object = model.fit_generator(train_generator,\n",
    "#             steps_per_epoch=ceil(len(train_samples)/batch_size),\n",
    "#             validation_data=validation_generator,\n",
    "#             validation_steps=ceil(len(validation_samples)/batch_size),\n",
    "#             epochs=20, callbacks=callbacks_list, verbose=1)\n",
    "\n",
    "# model.save('model_retrained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def balance_data(samples, visulization_flag ,N=60, K=1,  bins=100):\n",
    "#     \"\"\" Crop the top part of the steering angle histogram, by removing some images belong to those steering angels\n",
    "\n",
    "#     :param images: images arrays\n",
    "#     :param angles: angles arrays which\n",
    "#     :param n:  The values of the histogram bins\n",
    "#     :param bins: The edges of the bins. Length nbins + 1\n",
    "#     :param K: maximum number of max bins to be cropped\n",
    "#     :param N: the max number of the images which will be used for the bin\n",
    "#     :return: images, angle\n",
    "#     \"\"\"\n",
    "\n",
    "#     angles = samples[:,1].astype(np.float)\n",
    "#     n, bins, patches = plt.hist(angles, bins=bins, color= 'orange', linewidth=0.1)\n",
    "#     angles = np.array(angles)\n",
    "#     n = np.array(n)\n",
    "\n",
    "#     idx = n.argsort()[-K:][::-1]    # find the largest K bins\n",
    "#     del_ind = []                    # collect the index which will be removed from the data\n",
    "#     for i in range(K):\n",
    "#         if n[idx[i]] > N:\n",
    "#             ind = np.where((bins[idx[i]]<=angles) & (angles<bins[idx[i]+1]))\n",
    "#             ind = np.ravel(ind)\n",
    "#             np.random.shuffle(ind)\n",
    "#             del_ind.extend(ind[:len(ind)-N])\n",
    "\n",
    "#     # angles = np.delete(angles,del_ind)\n",
    "#     balanced_samples = [v for i, v in enumerate(samples) if i not in del_ind]\n",
    "#     balanced_angles = np.delete(angles,del_ind)\n",
    "\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.hist(balanced_angles, bins=bins, color= 'orange', linewidth=0.1)\n",
    "#     plt.title('modified histogram', fontsize=20)\n",
    "#     plt.xlabel('steering angle', fontsize=20)\n",
    "#     plt.ylabel('counts', fontsize=20)\n",
    "\n",
    "#     if visulization_flag:\n",
    "#         plt.figure\n",
    "#         plt.subplot(1,2,1)\n",
    "#         n, bins, patches = plt.hist(angles, bins=bins, color='orange', linewidth=0.1)\n",
    "#         plt.title('origin histogram', fontsize=20)\n",
    "#         plt.xlabel('steering angle', fontsize=20)\n",
    "#         plt.ylabel('counts', fontsize=20)\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.figure\n",
    "#         aa = np.append(balanced_angles, -balanced_angles)\n",
    "#         bb = np.append(aa, aa)\n",
    "#         plt.hist(bb, bins=bins, color='orange', linewidth=0.1)\n",
    "#         plt.title('final histogram', fontsize=20)\n",
    "#         plt.xlabel('steering angle', fontsize=20)\n",
    "#         plt.ylabel('counts', fontsize=20)\n",
    "#         plt.show()\n",
    "\n",
    "#     return balanced_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0f6af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
